{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Note: Une grande partie du code ci-dessous à été extrait ou inspiré de la ressource pour utiliser YAMNet. Crédit à https://www.tensorflow.org/hub/tutorials/yamnet et https://www.tensorflow.org/hub/tutorials/yamnet"
      ],
      "metadata": {
        "id": "zW8kd99368FP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Préparation"
      ],
      "metadata": {
        "id": "QuxFDZLRAUs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installation du bon TensorFlow\n",
        "!pip install -q \"tensorflow==2.11.*\"\n",
        "# tensorflow_io 0.28 is compatible with TensorFlow 2.11\n",
        "!pip install -q \"tensorflow_io==0.28.*\""
      ],
      "metadata": {
        "id": "aD5zc-MxceDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7f94f5-2ccd-410c-f4e3-db878c5382ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.27.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.27.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.66.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.25.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.7 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.11.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.11.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importer librairies\n",
        "from google.colab import files\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "import os\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_io as tfio"
      ],
      "metadata": {
        "id": "xuL_NDp8cfa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement du modèle YAMNet de Google\n",
        "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
        "yamnet_model = hub.load(yamnet_model_handle)"
      ],
      "metadata": {
        "id": "NLiUau4lchFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonctions utilitaires pour charger des fichiers audio et s'assurer que la fréquence d'échantillonnage est correcte\n",
        "@tf.function\n",
        "def load_wav_16k_mono(filename):\n",
        "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    wav, sample_rate = tf.audio.decode_wav(\n",
        "          file_contents,\n",
        "          desired_channels=1)\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ],
      "metadata": {
        "id": "OKTN8Es1c3Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNVCbAw-toOT",
        "outputId": "fc3aa492-21e7-4989-c4d2-a9d4be766bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chargement de la données\n",
        "file_path = '/content/annotations_clean_and_noised.xlsx'\n",
        "df = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "nyvEHHUSqKmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mettre les données dans le bon format (tensorflow)\n",
        "filenames = df['filename']\n",
        "targets = df['target']\n",
        "folds = df['fold']\n",
        "\n",
        "main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets, folds))\n",
        "main_ds.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIgAQI-Bd78x",
        "outputId": "e29a837e-b6f2-42e8-bdff-14caa99d46d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer les fichiers audio dans le format appropriés (établie par notre fonction intérieur)\n",
        "def load_wav_for_map(filename, label, fold):\n",
        "  return load_wav_16k_mono(filename), label, fold\n",
        "\n",
        "main_ds = main_ds.map(load_wav_for_map)\n",
        "main_ds.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "479o5SBVrFux",
        "outputId": "cc8f61b5-10c0-4bad-983a-65a8c27a3233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
            "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applique le modèle d'extraction d'embeddings à des données audio WAV\n",
        "def extract_embedding(wav_data, label, fold):\n",
        "  ''' run YAMNet to extract embedding from the wav data '''\n",
        "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
        "  num_embeddings = tf.shape(embeddings)[0]\n",
        "  return (embeddings,\n",
        "            tf.repeat(label, num_embeddings),\n",
        "            tf.repeat(fold, num_embeddings))\n",
        "\n",
        "# extraction d'embeddings pour chaque donnée\n",
        "main_ds = main_ds.map(extract_embedding).unbatch()\n",
        "main_ds.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl40-gtcrHtR",
        "outputId": "96b20491-c725-460e-bd83-9054cc7fd425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(1024,), dtype=tf.float32, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split des données et mise en cache\n",
        "cached_ds = main_ds.cache()\n",
        "train_ds = cached_ds.filter(lambda embedding, label, fold: fold < 7)\n",
        "val_ds = cached_ds.filter(lambda embedding, label, fold: fold == 7)\n",
        "\n",
        "# supprimer la colonne fold\n",
        "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
        "\n",
        "train_ds = train_ds.map(remove_fold_column)\n",
        "val_ds = val_ds.map(remove_fold_column)\n",
        "\n",
        "# mélange des données, batching, préchargement\n",
        "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "6826auhprJ5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instancier les noms des nouveaux labels\n",
        "my_classes = ['0', '1','2','3','4']\n",
        "map_class_to_id = {'0':0, '1':1,'2':2,'3':3,'4':4}"
      ],
      "metadata": {
        "id": "Ib10Xyrzrh_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement"
      ],
      "metadata": {
        "id": "GP9xuFSCAObK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrée : Un vecteur de taille 1024 (représentant un embedding)\n",
        "# Couche cachée : 3 couche dense avec 64 neurones et une activation ReLU\n",
        "# Couche sortie : nombre de classe\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
        "                          name='input_embedding'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(my_classes))\n",
        "], name='MLP')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMGYCcHSrL1L",
        "outputId": "163b5670-b1b0-4587-f3d8-f99b2ca31e0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"MLP\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 164,869\n",
            "Trainable params: 164,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prépare le modèle pour l'entraînement\n",
        "# Crossentropyloss/ softmax pour la classfication\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# EarlyStopping pour arrêter l'entraînement lorsque le modèle cesse d'améliorer\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=5,\n",
        "                                            restore_best_weights=True)"
      ],
      "metadata": {
        "id": "l6PZ9tuNrkAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement du modèle (Suivi de l'entrainement sur x epoch, en validation)\n",
        "history = model.fit(train_ds,\n",
        "                       epochs=100,\n",
        "                       validation_data=val_ds,\n",
        "                       callbacks=callback)"
      ],
      "metadata": {
        "id": "CEA9Jvqcrlyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae718d35-d128-4ca8-aa75-3bdc3f730ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "509/509 [==============================] - 153s 246ms/step - loss: 1.1110 - accuracy: 0.5237 - val_loss: 1.3221 - val_accuracy: 0.5039\n",
            "Epoch 2/100\n",
            "509/509 [==============================] - 2s 4ms/step - loss: 1.0732 - accuracy: 0.5295 - val_loss: 1.2916 - val_accuracy: 0.4976\n",
            "Epoch 3/100\n",
            "509/509 [==============================] - 3s 5ms/step - loss: 1.0613 - accuracy: 0.5368 - val_loss: 1.3651 - val_accuracy: 0.5016\n",
            "Epoch 4/100\n",
            "509/509 [==============================] - 2s 4ms/step - loss: 1.0511 - accuracy: 0.5412 - val_loss: 1.2652 - val_accuracy: 0.4937\n",
            "Epoch 5/100\n",
            "509/509 [==============================] - 2s 3ms/step - loss: 1.0425 - accuracy: 0.5425 - val_loss: 1.3323 - val_accuracy: 0.5024\n",
            "Epoch 6/100\n",
            "509/509 [==============================] - 2s 3ms/step - loss: 1.0310 - accuracy: 0.5471 - val_loss: 1.3666 - val_accuracy: 0.4972\n",
            "Epoch 7/100\n",
            "509/509 [==============================] - 2s 4ms/step - loss: 1.0219 - accuracy: 0.5528 - val_loss: 1.2806 - val_accuracy: 0.5099\n",
            "Epoch 8/100\n",
            "509/509 [==============================] - 3s 6ms/step - loss: 0.9978 - accuracy: 0.5574 - val_loss: 1.2834 - val_accuracy: 0.5193\n",
            "Epoch 9/100\n",
            "509/509 [==============================] - 2s 4ms/step - loss: 0.9850 - accuracy: 0.5587 - val_loss: 1.2888 - val_accuracy: 0.4968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sauvegarder le modèle entrainé"
      ],
      "metadata": {
        "id": "Mlq72-wc_zSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReduceMeanLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, axis=0, **kwargs):\n",
        "    super(ReduceMeanLayer, self).__init__(**kwargs)\n",
        "    self.axis = axis\n",
        "\n",
        "  def call(self, input):\n",
        "    return tf.math.reduce_mean(input, axis=self.axis)"
      ],
      "metadata": {
        "id": "jsvv7ISoAz3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_path = './Model_on_YAMNet_clean_and_noised'\n",
        "\n",
        "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
        "embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle,\n",
        "                                            trainable=False, name='YAMNet')\n",
        "_, embeddings_output, _ = embedding_extraction_layer(input_segment)\n",
        "serving_outputs = model(embeddings_output)\n",
        "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
        "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
        "serving_model.save(saved_model_path, include_optimizer=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpYr3v-9AcuD",
        "outputId": "2332881d-359e-44da-e2de-9f17de45ec2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PUAHDhKC4bV",
        "outputId": "e1ed6884-4c41-44d9-ff2f-6e4bea01275e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Téléchargement du modèle\n",
        "!cp -r /content/Model_on_YAMNet_clean_and_noised /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "KqgMCRFeC7kf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}